

## kafka 도입 시 문제
애플리케이션 입장에서 보면, 데이터를 저장하는 위치가 DB와 kafka 로 나뉘며,
이로 인해 위 두 데이터 저장소 간의 데이터 싱크를 고려해야 한다.

데이터를 저장하는 과정에서 네트워크 오류 등의 문제가 발생하게 되면 다음과 같은 문제들이 발생할 수 있다.
- DB에 저장 성공 (TX 커밋), 카프카에 publish 실패
    - 해당 경우는 트랜잭션 커밋 이후 kafka.send() 메서드를 호출하는 경우임
- 카프카에 publish 성공, DB에 저장 실패 (TX 롤백)
    - 해당 경우는 트랜잭션 내부에서 kafka.send() 메서드를 호출 후 트랜잭션을 커밋하는 경우임




##### 1. 만약 @Tx 내에 kafka send 가 있다면
kafka send 는 성공 -> DB 커밋은 실패한 경우 어떻게 처리할 지?
- kafka transaction 기능 사용
- 쓴다고 하더라도 결국 그 동작은
    - kafka tx 커밋 전에 topic produce
    - -> kafka tx 커밋 후 topic tx commit marking 하는 방식인데,
- kafka tx 커밋 후 topic 에 tx commit marking 하는 요청 보낼 때에도 network 이슈로 인해 실패할 가능성이 있어보인다.



##### 2. 만약 @Tx 완료 이후 kafka send 가 있다면
Kafka Send 에 실패한 경우에 대한 처리를 생각하면 다음과 같다.
- 1. Tx outbox pattern 사용
    - 1. Match Request 저장
    - 2. 'Match Request 저장 이벤트' DB에 저장
    - 3. (DB TX 커밋)
    - 4. kafka 로 이벤트 publish
    - 5. kafka 로 이벤트 발생 성공 시 DB에 저장된 'Match Request 저장 이벤트' 상태 '성공'으로 변경
    - 6. 발행에 실패한 데이터들을 주기적으로 polling 하여 재전송 시도
        - **근데 이 경우에도, kafka에 이벤트 send 했는데, 트랜잭션 커밋이 실패해서 상태가 '성공'으로 변경되지 않는다면, 중복 publish 문제가 발생**
-  2. fallback 을 열심히
    - 1. kafka retry N번
    - 2. 실패 시 dead letter queue 에 produce (여기서도 실패할 수 있으므로 n 번 retry)
    - 3. 실패 시 log
    - 그러나 마지막 3번의 과정에서 로그를 남기는 경우에도 예외가 발생할 수 있기 때문에 이 방법 역시도 100프로 안전한 것은 아니다.

결국 이러한 문제를 해결하기 위해서는 메세지가 중복 consume 하더라도 문제가 없도록,
즉 **멱등성**을 가지도록 consumer 로직을 작성해야 안전하다.
